\chapter{Теория вероятностей}
\label{chap:probability_theory}

\begin{supportbox}{Об этой главе}
Машинное обучение имеет дело с широким спектром неопределенностей (например, на этапе сбора данных), что делает использование вероятности фундаментальным. Здесь мы неформально рассматриваем основные понятия, связанные с распределениями вероятностей и плотностями вероятностей, которые полезны в основном тексте. В этом приложении вводится много понятий, но многие из них должны быть вам знакомы. Для более глубокого изложения вероятности в контексте машинного обучения и нейронных сетей см. \cite{bishop2006pattern,bishop2024deep}.
\end{supportbox}

\section{Основные законы вероятности}

Рассмотрим простую лотерею, где вы можете купить билеты с 3 возможными исходами: «без выигрыша», «малый выигрыш» и «крупный выигрыш». На каждые 10 билетов 1 из них будет с крупным выигрышем, 3 — с малым выигрышем, а 6 — без выигрыша. Мы можем представить это с помощью распределения вероятностей, описывающего относительную частоту трех событий (мы предполагаем неограниченный запас билетов):
%
\begin{gather*}
p(w=\text{`без выигрыша'})=6/10 \\
p(w=\text{`малый выигрыш'})=3/10\\
p(w=\text{`крупный выигрыш'})=1/10
\end{gather*}
%
Эквивалентно, мы можем связать целочисленное значение $w=\left\{1,2,3\right\}$ с тремя событиями и написать $p(w=1)=6/10$, $p(w=2)=3/10$ и $p(w=3)=1/10$. Мы называем $w$ \textbf{случайной величиной}. В дальнейшем мы всегда будем писать $p(w)$ вместо $p(w=i)$ для удобочитаемости, когда это возможно. Элементы распределения вероятностей должны быть положительными, и их сумма должна равняться единице:
%
$$
p(w)\ge0,\;\sum_wp(w)=1
$$
%
Пространство всех таких векторов называется \textbf{симплексом вероятностей}. 

\begin{tcolorbox}
Помните, что мы используем $\mathbf{p} \sim \Delta(n)$ для обозначения вектора размера $n$, принадлежащего симплексу вероятностей. 
\end{tcolorbox}

Предположим, мы вводим вторую случайную величину $r$, двоичную переменную, описывающую, является ли билет настоящим (1) или поддельным (2). Поддельные билеты более прибыльны, но в целом менее вероятны, как показано в Таблице \ref{tab:lottery_tickets}.
%
\begin{table}[h]
\centering
\caption{Относительная частота выигрыша в гипотетической лотерее, в которой билеты могут быть либо настоящими, либо поддельными, показана для набора из $100$ билетов.}
\label{tab:lottery_tickets}
\begin{tabular}{@{}lcc@{}}
\toprule
 & $r=1$ (настоящий билет) & $r=2$ (поддельный билет) \\ \midrule
$w=1$ (без выигрыша) & 58 & 2 \\
$w=2$ (малый выигрыш) & 27 & 3 \\
$w=3$ (крупный выигрыш) & 2 & 8 \\ \midrule
Сумма & 87 & 13 \\ \bottomrule
\end{tabular}
\end{table}

Мы можем использовать числа в таблице для описания \textbf{совместного распределения вероятностей}, описывающего вероятность того, что две случайные величины примут определенное значение совместно:
%
$$
p(r=2,w=3)=8/100
$$
%
В качестве альтернативы мы можем определить \textbf{условное распределение вероятностей}, например, отвечая на вопрос «\textit{какова вероятность определенного события при условии, что произошло другое событие?}»:
%
$$
p(r=1 \mid w=3) = \frac{p(r=1, w=3)}{p(w=3)} = 0.2
$$
%
Это называется \textbf{правилом произведения} вероятностей. Как и прежде, мы можем сделать нотацию менее многословной, используя случайную величину вместо ее значения:
%
\begin{equation}
p(r,w)=p(r\mid w)p(w)
\label{eq:product_rule}
\end{equation}
%
Если $p(r \mid w)=p(r)$, мы имеем $p(r,w)=p(r)p(w)$, и мы говорим, что две переменные \textbf{независимы}. Мы можем использовать условные вероятности для \textbf{маргинализации} по одной случайной величине:
%
\begin{equation}
p(w)=\sum_{r} p(w,r) = \sum_r p(w \mid r)p(r)
\label{eq:sum_rule}
\end{equation}

Это называется \textbf{правилом суммы} вероятностей. Правила произведения и суммы являются основными аксиомами, определяющими алгебру вероятностей. Комбинируя их, мы получаем фундаментальное \textbf{правило Байеса}:

\begin{equation}
    p(r\mid w)=\frac{p(w \mid r)p(r)}{p(w)} =\frac{p(w \mid r)p(r)}{\sum_{r^\prime}p(w \mid r^\prime)p(r^\prime)}
    \label{eq:bayes_rule}
\end{equation}

Правило Байеса позволяет нам «обращать» условные распределения, например, вычислять вероятность того, что выигрышный билет является настоящим или поддельным, зная относительные пропорции выигрышных билетов в обеих категориях (попробуйте).

\section{Вещественнозначные распределения вероятностей}

В вещественнозначном случае определение $p(x)$ сложнее, потому что $x$ может принимать бесконечное количество возможных значений, каждое из которых по определению имеет вероятность $0$. Однако мы можем обойти это, определив \textbf{кумулятивную функцию плотности} вероятности (CDF):

$$
P(x)=\int_{0}^xp(t)dt
$$

и определив функцию плотности вероятности $p(x)$ как ее производную. Мы игнорируем большинство тонкостей, связанных с работой с плотностями вероятностей, которые лучше всего рассматривать в контексте теории меры \cite{bogachev2007measure}. Мы только отмечаем, что правила произведения и суммы продолжают действовать в этом случае, если соответствующим образом заменить суммы на интегралы:

\begin{gather}
p(x,y)=p(x\mid y)p(y) \\
p(x)=\int_y p(x \mid y)p(y)dy
\end{gather}

Обратите внимание, что плотности вероятностей не обязаны быть меньше единицы.

\section{Распространенные распределения вероятностей}

Предыдущие случайные величины являются примером \textbf{категориальных распределений вероятностей}, описывающих ситуацию, в которой переменная может принимать одно из $k$ возможных значений. Мы можем записать это компактно, определив как $\mathbf{p} \sim \Delta(k)$ вектор вероятностей, и как $\mathbf{x} \sim \text{Binary}(k)$ one-hot кодирование наблюдаемого класса:
%
$$
p(\mathbf{x})=\text{Cat}(\mathbf{x}; \mathbf{p})=\prod_ip_i^{x_i}
$$
%
Мы используем точку с запятой, чтобы отличить вход распределения от его параметров. Если $k=2$, мы можем эквивалентно переписать распределение с одним скалярным значением $p$. Результирующее распределение называется \textbf{распределением Бернулли}:
%
$$
p(x)=\text{Bern}(x; p)= p^x(1-p)^{(1-x)}
$$
%
В непрерывном случае мы будем неоднократно иметь дело с \textbf{гауссовым} распределением, обозначаемым как $\mathcal{N}(x; \mu, \sigma^2)$, описывающим колоколообразную вероятность с центром в $\mu$ (среднее) и разбросом $\sigma^2$ (дисперсия):
%
$$
p(x)=\mathcal{N}(x;\mu,\sigma^2)= \frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)
$$
%
В простейшем случае нулевого среднего и единичной дисперсии, $\mu=0$, $\sigma^2=1$, это также называется \textbf{нормальным распределением}. Для вектора $\mathbf{x} \sim (k)$, многомерный вариант гауссова распределения получается путем рассмотрения вектора среднего $\mathbf{\mu} \sim (k)$ и ковариационной матрицы $\Sigma \sim (k,k)$:
%
$$
p(\mathbf{x})=\mathcal{N}(\mathbf{x};\mu, \Sigma)= \left(2\pi\right)^{-k/2}\det(\Sigma)^{-1/2}\exp\left((\mathbf{x}-\mu)^\top\Sigma^{-1}(\mathbf{x}-\mu)\right)
$$
%
Два интересных случая — это гауссовы распределения с диагональной ковариационной матрицей и еще более простой \textbf{изотропный} гауссиан, имеющий диагональную ковариацию со всеми одинаковыми элементами:
%
$$
\Sigma=\sigma^2\mathbf{I}
$$
%
Первый можно представить как выровненный по осям эллипсоид, изотропный — как выровненную по осям сферу.

\section{Моменты и математические ожидания}

Во многих случаях нам нужно обобщить распределение вероятностей одним или несколькими значениями. Иногда достаточно конечного числа значений: например, доступ к $\mathbf{p}$ для категориального распределения или к $\mu$ и $\sigma^2$ для гауссова распределения полностью описывает само распределение. Они называются \textbf{достаточными статистиками}. 

В более общем случае, для любой заданной функции $f(x)$ мы можем определить ее \textbf{математическое ожидание} как:
%
\begin{equation}
\mathbb{E}_{p(x)}\left[f(x)\right]=\sum_{x}f(x)p(x)
\label{eq:expected_value}
\end{equation}
%
В вещественнозначном случае мы получаем то же определение, заменяя сумму на интеграл. Особый интерес представляют случаи, когда $f(x)=x^p$, и мы имеем \textbf{моменты} (порядка $p$) распределения, причем $p=1$ называется \textbf{средним} распределения:
%
$$
\mathbb{E}_{p(x)}\left[x\right]=\sum_{x}xp(x)
$$
%
Мы можем захотеть оценить некоторые математические ожидания, не имея доступа к базовому распределению вероятностей. Если у нас есть способ выборки элементов из $p(x)$, мы можем применить так называемый \textbf{оценщик Монте-Карло}:
%
\begin{equation}
\mathbb{E}_{p(x)}\left[f(x)\right]\approx \frac{1}{n}\sum_{x_i \sim p(x)}f(x_i)
\label{eq:montecarlo_estimation}
\end{equation}
%
где $n$ контролирует качество оценки, и мы используем $x_i \sim p(x)$ для обозначения операции выборки из распределения вероятностей $p(x)$. Для момента первого порядка это сводится к очень знакомой нотации для вычисления среднего значения величины по нескольким измерениям:

$$
\mathbb{E}_{p(x)}\left[x\right]=\frac{1}{n}\sum_{x_i \sim p(x)}x_i
$$

\section{Расстояние между распределениями вероятностей}

Иногда нам также может потребоваться некоторая форма расстояния между распределениями вероятностей, чтобы оценить, насколько близки два распределения. Дивергенция \textbf{Кульбака-Лейблера} (KL) между $p(x)$ и $q(x)$ является распространенным выбором:
%
$$
\text{KL}(p \;\lVert\; q) = \int p(x)\log\frac{p(x)}{q(x)}dx
$$
%
Дивергенция KL не является правильной метрикой (она асимметрична и не удовлетворяет неравенству треугольника). Она ограничена снизу нулем, но не ограничена сверху. Дивергенция может быть определена только в том случае, если для любого $x$, такого что $q(x)=0$, тогда $p(x)=0$ (т.е. носитель $p$ является подмножеством носителя $q$). Минимум $0$ достигается, когда два распределения идентичны. Дивергенцию KL можно записать как математическое ожидание, следовательно, ее можно оценить с помощью выборки Монте-Карло, как в \eqref{eq:montecarlo_estimation}.

\section{Оценка максимального правдоподобия} \addclock
\label{sec:maximum_likelihood_estimation}

Выборка Монте-Карло показывает, что мы можем оценивать интересующие нас величины, касающиеся распределения вероятностей, если у нас есть доступ к выборкам из него. Однако мы можем быть заинтересованы в оценке самого распределения вероятностей. Предположим, у нас есть предположение о его функциональной форме $f(x; s)$, где $s$ — это достаточные статистики (например, среднее и дисперсия гауссова распределения), и набор из $n$ выборок $x_i \sim p(x)$. Мы называем эти выборки одинаковыми (потому что они происходят из одного и того же распределения вероятностей) и независимо распределенными, короче, i.i.d. Из-за независимости их совместное распределение факторизуется для любого выбора $s$:
%
$$
p(x_1, \ldots, x_n)=\prod_{i=1}^n f(x_i; s)
$$
%
Большие произведения неудобны в вычислительном отношении, но мы можем эквивалентно переписать это как сумму с помощью логарифмического преобразования:
%
$$
L(s)= \sum_{i=1}^n\log(f(x_i;s))
$$
%
Нахождение параметров $s$, которые максимизируют предыдущую величину, называется подходом \textbf{максимального правдоподобия} (МП). Из-за его важности мы кратко переформулируем его ниже.

\newpage
\begin{definition}[Максимальное правдоподобие] \addbottle
Для параметрического семейства распределений вероятностей $f(x; s)$ и набора из $n$ значений $\left\{x_i\right\}_{i=1}^n$, которые являются i.i.d. выборками из неизвестного распределения $p(x)$, наилучшее приближение к $p(x)$ согласно принципу \textbf{максимального правдоподобия} (МП) задается как:
%
$$
s^*=\underset{s}{\arg\max} \sum_{i=1}^n \log(f(x_i;s))
$$
\end{definition}

Если $f$ дифференцируема, мы можем максимизировать целевую функцию с помощью градиентного спуска. Это основной подход, которому мы следуем для обучения дифференцируемых моделей. Пока мы завершаем приложение, описывая простые примеры оценки МП в случае стандартных распределений вероятностей. Мы не приводим подробных вычислений, за которыми мы отсылаем к \cite{bishop2006pattern,bishop2024deep}.
%
\subsubsection*{Максимальное правдоподобие для распределения Бернулли}
%
Рассмотрим сначала случай распределения Бернулли с неизвестным параметром $p$. В этом случае оценщик МП равен:
%
$$
p^*=\frac{\sum_i x_i}{n}
$$
%
что является просто отношением положительных выборок ко всему набору данных.

\subsubsection*{Максимальное правдоподобие для гауссова распределения}

Для гауссова распределения мы можем переписать его логарифм правдоподобия как:
%
$$
L(\mu, \sigma^2) = - \frac{n}{2}\log(2\pi \sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2
$$
%
Максимизация по $\mu$ и $\sigma^2$ по отдельности возвращает известные правила для вычисления эмпирического среднего и дисперсии гауссова распределения:
%
\begin{gather}
\mu^*=\frac{1}{n}\sum_i x_i \\\sigma^{2*}=\frac{1}{n}\sum_i(x_i-\mu^*)^2
\end{gather}
%
Их можно вычислять последовательно. Поскольку мы используем оценку для среднего внутри формулы дисперсии, можно показать, что результирующая оценка немного смещена. Это можно исправить, изменив нормировочный член на $\frac{1}{n-1}$; это известно как поправка Бесселя.\footnote{\url{https://en.wikipedia.org/wiki/Bessel\%27s\_correction}} Для больших $n$ разница между двумя вариантами минимальна.
